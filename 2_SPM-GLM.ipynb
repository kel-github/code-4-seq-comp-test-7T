{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run SPM GLM to get condition beta weights and residual files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over subject and TR, thereby concatenating across session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201128-12:11:49,525 nipype.utils WARNING:\n",
      "\t A newer version (1.5.1) of nipy/nipype is available. You are using 1.5.0\n"
     ]
    }
   ],
   "source": [
    "from bids.layout import BIDSLayout\n",
    "from nipype.interfaces import afni \n",
    "from nipype.interfaces.io import BIDSDataGrabber, DataFinder, DataSink, DataGrabber\n",
    "import nipype.pipeline as pe\n",
    "import nipype as ni\n",
    "from nipype.interfaces.utility import Function\n",
    "import nipype.interfaces.fsl.maths as fsl\n",
    "from nipype.interfaces import spm as spm\n",
    "from nipype.algorithms import modelgen as mgen\n",
    "from nipype.algorithms.misc import Gunzip \n",
    "import pandas as pd\n",
    "import os, re, json\n",
    "# https://nipype.readthedocs.io/en/0.11.0/users/spmmcr.html\n",
    "\n",
    "matlab_cmd = '/opt/spm12-r7219/run_spm12.sh /opt/matlabmcr-2010a/v713/ script'\n",
    "spm.SPMCommand.set_mlab_paths(matlab_cmd=matlab_cmd, use_mcr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/bids/layout/models.py:102: FutureWarning: The 'extension' entity currently excludes the leading dot ('.'). As of version 0.14.0, it will include the leading dot. To suppress this warning and include the leading dot, use `bids.config.set_option('extension_initial_dot', True)`.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "Basedir = \"/scratch/qbi/uqkgarn1/STRIWP1/\"\n",
    "layout = BIDSLayout(Basedir)\n",
    "subs = layout.get_subjects()\n",
    "\n",
    "glm = pe.Workflow(name=\"glms\") # workflow to run the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data grabbing and saving nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I copied the motion files from the derivatives/etc path to derivatives/glm/sub-etc and I removed the T2 echo-1 and echo-2 .nii.gz data from the func folder below. I also removed the echo 2 motion files from the same folder, and the bjson files (renaming echo 1 of the 700 TR to fit the below field template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CODE DEFINITELY WORKS\n",
    "dgT2s = pe.Node(DataGrabber(infields=['sub', 'TR'], \n",
    "                            outfields=['func','motion','onsets','bjson','mask']), name='T2-grabber')\n",
    "dgT2s.inputs.base_dir = \"/scratch/qbi/uqkgarn1/STRIWP1/\"\n",
    "dgT2s.inputs.sort_filelist = True\n",
    "dgT2s.inputs.template='*'\n",
    "dgT2s.inputs.template_args = {'func': [['sub', 'sub', 'TR']],\n",
    "                              'motion':[['sub', 'sub', 'TR']],\n",
    "                              'onsets':[['sub', 'sub', 'TR']],\n",
    "                              'bjson':[['sub', 'sub', 'TR']],\n",
    "                              'mask':[['sub', 'sub', 'TR']]}\n",
    "dgT2s.inputs.field_template = {'func': '/scratch/qbi/uqkgarn1/STRIWP1/derivatives/sub-%s/ses-*/func/sub-%s_*TR%s_space-T1w_desc-preproc_bold.nii.gz',\n",
    "                               'motion': '/scratch/qbi/uqkgarn1/STRIWP1/derivatives/glm/sub-%s/ses-*/func/sub-%s_*-TR%s*desc-motion_regressors.txt',\n",
    "                               'onsets': '/scratch/qbi/uqkgarn1/STRIWP1/derivatives/sub-%s/ses-*/func/sub-%s_*-TR%s_glm_onsets.json',\n",
    "                               'bjson': '/scratch/qbi/uqkgarn1/STRIWP1/derivatives/sub-%s/ses-*/func/sub-%s_*-TR%s*space-T1w_desc-preproc_bold.json',\n",
    "                               'mask': '/scratch/qbi/uqkgarn1/STRIWP1/derivatives/sub-%s/ses-02/func/sub-%s_*TR%s_space-T1w_desc-brain_mask.nii.gz'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging\n",
    "# dgT2s.inputs.sub = '01'\n",
    "# dgT2s.inputs.TR = '1510'\n",
    "# res = dgT2s.run()\n",
    "# res.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sub', ['01', '02', '03', '04', '05']), ('TR', ['700', '1510', '1920'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THIS WORKS\n",
    "T2inf = pe.Node(ni.IdentityInterface(fields=['sub', 'TR']),\n",
    "                   name='T2-info')\n",
    "T2inf.iterables = [('sub', ['01', '02', '03', '04', '05']), ('TR', ['700', '1510', '1920'])]\n",
    "#T2inf.iterables = [('sub', ['01']), ('TR', ['1510'])]\n",
    "T2inf.iterables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSubPath(fullFilePath):\n",
    "    # function to split filepath into constituent parts, then print string to add as input to DataSink for the container string\n",
    "    # given the full filepath, this extracts the subject folder and TR strings for input\n",
    "    # into DataSink\n",
    "    import os\n",
    "    import re\n",
    "    fname = os.path.normpath(fullFilePath[0])\n",
    "    fname\n",
    "    l = fname.split(os.sep)\n",
    "    TR = re.search('.*acq-TR([0-9]*)_.*',l[-1])\n",
    "    TR = str(int(TR.group(1)))\n",
    "    name = [s for s in l if re.search('sub', s)][0]\n",
    "    name = [name, \"TR\"+TR]\n",
    "    name\n",
    "    name = '/'.join(name)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sink\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pe.Node(DataSink(), name='sink-stuff')\n",
    "ds.inputs.base_directory = \"/scratch/qbi/uqkgarn1/STRIWP1/derivatives/glmTDFAST/\"\n",
    "# glm Time and Dispersion derivatives and FAST correction of serial correlations\n",
    "substitutions = [('_TR_([0-9]*)_sub_([0-9]*)', '')]\n",
    "ds.inputs.regexp_substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get design info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input function should be a list of the prt files, taken across sessions, for each TR\n",
    "def getOnsetsJson(input_files):\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    import json\n",
    "    prt_output = [] #prt=protocol\n",
    "    count = 0\n",
    "    for f in input_files: \n",
    "        count = count + 1\n",
    "        with open(f, \"r+\") as file:\n",
    "            data = json.load(file)\n",
    "            prt_output.insert(count, \n",
    "                              Bunch(conditions=data['names'],\n",
    "                                    onsets=data['onsets'],\n",
    "                                    durations=data['durations']))\n",
    "    return prt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "getOnsets = pe.Node(Function(input_names=['input_files'],\n",
    "                             output_names=['prt_output'],\n",
    "                             function=getOnsetsJson),\n",
    "                    name='get_prt_onsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gunzip Nodes\n",
    "\n",
    "1 for functional data, 1 for mask (condense during finesse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gunzipfunc = pe.MapNode(Gunzip(), name='gunzipfunc', iterfield=['in_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmask = pe.Node(Gunzip(), name='m-zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth the functional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth = pe.Node(spm.Smooth(), name='smoooooth')\n",
    "# smooth.inputs.fwhm = [3, 3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the TR for the model spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input function should be a list of the prt files, taken across sessions, for each TR\n",
    "def getTRJson(input_files):\n",
    "    import json\n",
    "    with open(input_files[0], \"r+\") as file:\n",
    "            data = json.load(file)\n",
    "            TR = data['RepetitionTime'] \n",
    "    if TR < .5:\n",
    "        TR = 1.92\n",
    "    return TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "getTR = pe.Node(Function(input_names=['input_files'],\n",
    "                         output_names=['TR'],\n",
    "                         function=getTRJson),\n",
    "                name='get_TR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSavFol(TR):\n",
    "    # function to append the TR to a name for the save folder\n",
    "    name = \"TR\" + TR\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify GLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpecifyModel - Generates SPM-specific Model\n",
    "modelspec = pe.Node(mgen.SpecifySPMModel(concatenate_runs=False,\n",
    "                                         input_units='secs',\n",
    "                                         output_units='secs',\n",
    "                                         high_pass_filter_cutoff=128),\n",
    "                    name=\"modelspec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level1Design - Generates an SPM design matrix\n",
    "level1design = pe.Node(spm.Level1Design(bases={'hrf': {'derivs': [1, 1]}},\n",
    "                                 timing_units='secs',\n",
    "                                 model_serial_correlations='FAST'),\n",
    "                       name=\"level1design\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EstimateModel - estimate the parameters of the model\n",
    "estimate = pe.Node(spm.EstimateModel(estimation_method={'Classical': 1},\n",
    "                                     write_residuals=False),\n",
    "                                     name=\"estimate\")\n",
    "\n",
    "# inputs\n",
    "# spm mat file\n",
    "# outputs\n",
    "# beta_images\n",
    "# residual_images\n",
    "# spm_mat_file\n",
    "\n",
    "# will input the spm.mat files output by the design module above\n",
    "\n",
    "# # EstimateContrast - estimates contrasts\n",
    "# level1conest = pe.Node(spm.EstimateContrast(), name=\"level1conest\")\n",
    "# level1conest.inputs.contrasts = contrast_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### esimating beta weights and some contrasts due to below from Puckett's paper:\n",
    "\n",
    "All functional time-courses were scaled to percent signal change (i.e.\n",
    "each voxel time series was scaled to have a mean of 100) before calculating a multiple linear regression. The regression model contained 2\n",
    "regressors corresponding to each experimental condition (simple and\n",
    "complex movement, Fig. 1C) generated by convolving the stimulus\n",
    "timing of each condition with a canonical hemodynamic response function model. A further 6 regressors, estimated from the volume registration step and representing the participant's head movement during the\n",
    "scan, were also included. From the calculated regression model, contrast to-noise ratio (CNR) was calculated on a voxel-wise basis for each condition by dividing each voxel's beta or linear contrast value from the\n",
    "general linear model analysis by the standard deviation of the residual\n",
    "error of the time-series for that voxel. Results from the single-subject\n",
    "regression analysis \n",
    "\n",
    "So I can just take each regressor and I will take the RMSE of the effect sizes (making negative positive) and divide that by the standard deviation of the residuals, within each region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify GLM contrasts (Canonical only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = ['att_left_5','att_left_8','att_right_5','att_right_8','ll','lh','hh','hl','exp_high','exp_low','unexp_high','unexp_low','right_hand','left_hand','invalid']\n",
    "# #len(names)\n",
    "# attend_lvr = ('att_lvr', 'T', names, [-1, -1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "# attend_p = ('att_p', 'T', names, [-1, 1, -1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "# attend_interaction = ('att_int', 'T', names, [1, -1, -1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "# attend_cue = ('att_cue', 'F', [attend_lvr, attend_p, attend_interaction])\n",
    "# # attend_cue = ('att_cue', 'F', names, [[-1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "# #                                       [0, 0, -1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "# #                                       [1, -1, -1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "# llvhh = ('llvhh', 'T', names, [0, 0, 0, 0, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "# lhvhl = ('lhvhl', 'T', names, [0, 0, 0, 0, 0, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
    "# relval = ('relval', 'T', names, [0, 0, 0, 0, 1, -1, -1, 1, 0, 0, 0, 0, 0, 0, 0])\n",
    "# value_cue = ('value_cue', 'F', [llvhh, lhvhl, relval])\n",
    "# # value_cue = ('value_cue', 'F', names, [[0, 0, 0, 0, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "# #                                        [0, 0, 0, 0, 0, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "# #                                        [0, 0, 0, 0, 1, -1, -1, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
    "# hand = ('hand', 'T', names, [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, 0])\n",
    "# contrasts = [attend_lvr, attend_p, attend_interaction, attend_cue, llvhh, lhvhl, relval, value_cue, hand]\n",
    "# #contrasts\n",
    "# hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify GLM contrasts (when using Time and Dispersion Derivatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = ['att_left_5','att_left_5T','att_left_5D','att_left_8','att_left_8T','att_left_8D',\n",
    "#          'att_right_5','att_right_5T','att_right_5D','att_right_8','att_right_8T','att_right_8D',\n",
    "#          'll','llT','llD',\n",
    "#          'lh','lhT','lhD',\n",
    "#          'hh','hhT','hhD',\n",
    "#          'hl','hlT','hlD',\n",
    "#          'exp_high','exp_highT','exp_highD',\n",
    "#          'exp_low','exp_lowT','exp_lowD',\n",
    "#          'unexp_high','unexp_highT','unexp_highD',\n",
    "#          'unexp_low','unexp_lowT','unexp_lowD',\n",
    "#          'right_hand','right_handT','right_handD',\n",
    "#          'left_hand','left_handT','left_handD',\n",
    "#          'invalid','invalidT','invalidD']\n",
    "\n",
    "\n",
    "def do_name_lookup(name, lookup):\n",
    "    if name in lookup.keys():\n",
    "        return lookup[name]\n",
    "    else:\n",
    "        return 0\n",
    "names = ['att_left_5','att_left_8','att_right_5','att_right_8','ll','lh','hh','hl','exp_high','exp_low','unexp_high','unexp_low','right_hand','left_hand','invalid']\n",
    "# Spatial cue related contrasts\n",
    "attend_lvr = ('att_lvr', 'T', names, [do_name_lookup(name, {'att_left_5':1, 'att_left_8':1, 'att_right_5':-1, 'att_right_8':-1}) for name in names])\n",
    "attend_p = ('att_p', 'T', names, [do_name_lookup(name, {'att_left_5':-1, 'att_left_8':1, 'att_right_5':-1, 'att_right_8':1}) for name in names])\n",
    "attend_interaction = ('att_int', 'T', names, [do_name_lookup(name, {'att_left_5':1, 'att_left_8':-1, 'att_right_5':-1, 'att_right_8':1}) for name in names])\n",
    "attend_cue = ('att_cue', 'F', [attend_lvr, attend_p, attend_interaction])                                             \n",
    "# # Value contrasts\n",
    "llvhh = ('llvhh', 'T', names, [do_name_lookup(name, {'ll':-1, 'hh':1}) for name in names])\n",
    "lhvhl = ('lhvhl', 'T', names, [do_name_lookup(name, {'lh':-1, 'hl':1}) for name in names])\n",
    "relval = ('relval', 'T', names, [do_name_lookup(name, {'ll':1, 'lh':-1, 'hh':-1, 'hl':1}) for name in names])\n",
    "value_cue = ('value_cue', 'F', [llvhh, lhvhl])\n",
    "# Motoric contrast\n",
    "hand = ('hand', 'T', names, [do_name_lookup(name, {'right_hand':-1, 'left_hand':1}) for name in names])\n",
    "contrasts = [attend_lvr, attend_p, attend_interaction, attend_cue, llvhh, lhvhl, relval, value_cue, hand]\n",
    "# contrasts = [attend_lvr, llvhh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( [do_name_lookup(name, {'att_left_5':1, 'att_left_8':1, 'att_right_5':-1, 'att_right_8':-1}) for name in names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conts = pe.Node(spm.EstimateContrast(contrasts=contrasts),\n",
    "                                     name=\"conts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glm.connect([(T2inf, dgT2s, [('sub',  'sub')]), \n",
    "#              (T2inf, dgT2s, [('TR',   'TR')]),\n",
    "#              (dgT2s, ds, [(('motion', printSubPath),\n",
    "#                             'container')]),\n",
    "#              (dgT2s, getOnsets, [('onsets', 'input_files')]),\n",
    "#              (dgT2s, gunzipfunc, [('func', 'in_file')]),\n",
    "#              (dgT2s, gmask, [('mask', 'in_file')]),\n",
    "#              (gunzipfunc, smooth, [('out_file', 'in_files')]),\n",
    "#              (dgT2s, getTR, [('bjson', 'input_files')]),\n",
    "#              (getTR, modelspec, [('TR', 'time_repetition')]),\n",
    "#              (dgT2s, modelspec, [('motion', 'realignment_parameters')]),\n",
    "#              (getOnsets, modelspec, [('prt_output', 'subject_info')]),\n",
    "#              (smooth, modelspec, [('smoothed_files', 'functional_runs')]),\n",
    "#              (getTR, level1design, [('TR', 'interscan_interval')]),\n",
    "#              (modelspec, level1design, [('session_info', 'session_info')]),\n",
    "#              (gmask, level1design, [('out_file', 'mask_image')]),\n",
    "#              (level1design, estimate, [('spm_mat_file', 'spm_mat_file')]),\n",
    "#              (estimate, ds, [('beta_images', 'FLGLM.@beta')]),\n",
    "#              (estimate, ds, [('residual_image', 'FLGLM.@resid')]),\n",
    "#              (estimate, conts, [('beta_images', 'beta_images')]),\n",
    "#              (estimate, conts, [('residual_image', 'residual_image')]),\n",
    "#              (estimate, conts, [('spm_mat_file','spm_mat_file')]),\n",
    "#              (conts, ds, [('con_images', 'FLGLM.@con')]),\n",
    "#              (conts, ds, [('spmT_images', 'FLGLM.@T')]),\n",
    "#              (conts, ds, [('spm_mat_file', 'FLGLM.@spm')])\n",
    "#             ])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm.connect([(T2inf, dgT2s, [('sub',  'sub')]), \n",
    "             (T2inf, dgT2s, [('TR',   'TR')]),\n",
    "             (dgT2s, ds, [(('motion', printSubPath),\n",
    "                            'container')]),\n",
    "             (dgT2s, getOnsets, [('onsets', 'input_files')]),\n",
    "             (dgT2s, gunzipfunc, [('func', 'in_file')]),\n",
    "             (dgT2s, gmask, [('mask', 'in_file')]),\n",
    "             (dgT2s, getTR, [('bjson', 'input_files')]),\n",
    "             (getTR, modelspec, [('TR', 'time_repetition')]),\n",
    "             (dgT2s, modelspec, [('motion', 'realignment_parameters')]),\n",
    "             (getOnsets, modelspec, [('prt_output', 'subject_info')]),\n",
    "             (gunzipfunc, modelspec, [('out_file', 'functional_runs')]),\n",
    "             (getTR, level1design, [('TR', 'interscan_interval')]),\n",
    "             (modelspec, level1design, [('session_info', 'session_info')]),\n",
    "             (gmask, level1design, [('out_file', 'mask_image')]),\n",
    "             (level1design, estimate, [('spm_mat_file', 'spm_mat_file')]),\n",
    "             (estimate, ds, [('beta_images', 'FLGLM.@beta')]),\n",
    "             (estimate, ds, [('residual_image', 'FLGLM.@resid')]),\n",
    "             (estimate, conts, [('beta_images', 'beta_images')]),\n",
    "             (estimate, conts, [('residual_image', 'residual_image')]),\n",
    "             (estimate, conts, [('spm_mat_file','spm_mat_file')]),\n",
    "             (conts, ds, [('con_images', 'FLGLM.@con')]),\n",
    "             (conts, ds, [('spmT_images', 'FLGLM.@T')]),\n",
    "             (conts, ds, [('spm_mat_file', 'FLGLM.@spm')])\n",
    "            ])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201128-12:12:08,827 nipype.workflow INFO:\n",
      "\t Workflow glms settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "201128-12:12:09,62 nipype.workflow INFO:\n",
      "\t Running serially.\n",
      "201128-12:12:09,63 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"glms.T2-grabber\" in \"/tmp/tmpsxcu_2wk/glms/_TR_1920_sub_05/T2-grabber\".\n",
      "201128-12:12:09,68 nipype.workflow INFO:\n",
      "\t [Node] Running \"T2-grabber\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "201128-12:12:09,78 nipype.workflow INFO:\n",
      "\t [Node] Finished \"glms.T2-grabber\".\n",
      "201128-12:12:09,79 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"glms.get_TR\" in \"/tmp/tmpf2csv9is/glms/_TR_1920_sub_05/get_TR\".\n",
      "201128-12:12:09,83 nipype.workflow INFO:\n",
      "\t [Node] Running \"get_TR\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "201128-12:12:09,87 nipype.workflow INFO:\n",
      "\t [Node] Finished \"glms.get_TR\".\n",
      "201128-12:12:09,88 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"glms.m-zip\" in \"/tmp/tmppv3i1zsc/glms/_TR_1920_sub_05/m-zip\".\n",
      "201128-12:12:09,91 nipype.workflow INFO:\n",
      "\t [Node] Running \"m-zip\" (\"nipype.algorithms.misc.Gunzip\")\n",
      "201128-12:12:09,109 nipype.workflow INFO:\n",
      "\t [Node] Finished \"glms.m-zip\".\n",
      "201128-12:12:09,109 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"glms.gunzipfunc\" in \"/tmp/tmpnhb7yutf/glms/_TR_1920_sub_05/gunzipfunc\".\n",
      "201128-12:12:09,114 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_gunzipfunc0\" in \"/tmp/tmpnhb7yutf/glms/_TR_1920_sub_05/gunzipfunc/mapflow/_gunzipfunc0\".\n",
      "201128-12:12:09,117 nipype.workflow INFO:\n",
      "\t [Node] Running \"_gunzipfunc0\" (\"nipype.algorithms.misc.Gunzip\")\n",
      "201128-12:12:14,527 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_gunzipfunc0\".\n",
      "201128-12:12:14,529 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_gunzipfunc1\" in \"/tmp/tmpnhb7yutf/glms/_TR_1920_sub_05/gunzipfunc/mapflow/_gunzipfunc1\".\n",
      "201128-12:12:14,533 nipype.workflow INFO:\n",
      "\t [Node] Running \"_gunzipfunc1\" (\"nipype.algorithms.misc.Gunzip\")\n",
      "201128-12:12:20,16 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_gunzipfunc1\".\n",
      "201128-12:12:20,18 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_gunzipfunc2\" in \"/tmp/tmpnhb7yutf/glms/_TR_1920_sub_05/gunzipfunc/mapflow/_gunzipfunc2\".\n",
      "201128-12:12:20,22 nipype.workflow INFO:\n",
      "\t [Node] Running \"_gunzipfunc2\" (\"nipype.algorithms.misc.Gunzip\")\n"
     ]
    }
   ],
   "source": [
    "glm.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
