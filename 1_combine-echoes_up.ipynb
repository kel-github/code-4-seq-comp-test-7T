{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine echoes for each subject and session\n",
    "\n",
    "Written by K. Garner, March 2021\n",
    "\n",
    "Use this code first, to combine the multiecho images, using the weighted summation method from Pucket et al: https://www.sciencedirect.com/science/article/pii/S1053811917310194?via%3Dihub\n",
    "Based on: https://github.com/Donders-Institute/multiecho/blob/master/multiecho/combination.py\n",
    "\n",
    "Run manually on each sub and session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210303-12:27:18,994 nipype.utils WARNING:\n",
      "\t A newer version (1.5.1) of nipy/nipype is available. You are using 1.5.0\n"
     ]
    }
   ],
   "source": [
    "from nipype.interfaces.io import DataGrabber as dgrb\n",
    "import nipype.pipeline as pe\n",
    "import nipype as ni\n",
    "\n",
    "from typing import List, Optional, Tuple\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define session variables\n",
    "sub = '05'\n",
    "ses = '03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = pe.Node(dgrb(infields=['sub', 'sess'], \n",
    "                            outfields=['func']), name='get-data')\n",
    "dg.inputs.sort_filelist = True\n",
    "dg.inputs.template='*'\n",
    "dg.inputs.template_args = {'func': [['sub', 'sess', 'sub']]}\n",
    "dg.inputs.field_template = {'func': '/scratch/qbi/uqkgarn1/STRIWP1/derivatives/sub-%s/ses-%s/func/sub-%s_*-TR700_*_space-T1w_desc-preproc_bold.nii.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210303-12:27:19,290 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"get-data\" in \"/tmp/tmpll8pdeiy/get-data\".\n",
      "210303-12:27:19,297 nipype.workflow INFO:\n",
      "\t [Node] Running \"get-data\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "210303-12:27:19,305 nipype.workflow INFO:\n",
      "\t [Node] Finished \"get-data\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "func = ['/scratch/qbi/uqkgarn1/STRIWP1/derivatives/sub-05/ses-03/func/sub-05_ses-03_task-learnAtt_acq-TR700_echo-1_space-T1w_desc-preproc_bold.nii.gz', '/scratch/qbi/uqkgarn1/STRIWP1/derivatives/sub-05/ses-03/func/sub-05_ses-03_task-learnAtt_acq-TR700_echo-2_space-T1w_desc-preproc_bold.nii.gz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg.inputs.sub = sub\n",
    "dg.inputs.sess = ses\n",
    "fs = dg.run()\n",
    "fs.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data and echoes in correct format for subsequent functions\n",
    "datafiles = fs.outputs.func\n",
    "TEs = [10, 30.56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def org_data(datafiles, TEs):\n",
    "#     \"\"\"Load all echoes and their TEs.\n",
    "#     Return a list of tuples like:\n",
    "#     [(echo1, TE1), (echo2, TE2), ..., (echoN, TEN)]\n",
    "#     Here, echoN is a numpy array of loaded data.\n",
    "#     \"\"\"\n",
    "#     s = np.argsort(TEs)\n",
    "#     TEs = np.array(TEs)[s]\n",
    "#     datafiles = np.array(datafiles)[s]\n",
    "#     return[(nib.load(str(datafile)), TEs[n]) for n, datafile in enumerate(datafiles)], list(datafiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def org_data(datafiles, TEs):\n",
    "    \"\"\"Load all echoes and their TEs.\n",
    "    Return a list of tuples like:\n",
    "    [(echo1, TE1), (echo2, TE2), ..., (echoN, TEN)]\n",
    "    Here, echoN is a numpy array of loaded data.\n",
    "    \"\"\"\n",
    "    s = np.argsort(TEs)\n",
    "    TEs = np.array(TEs)[s]\n",
    "    datafiles = np.array(datafiles)[s]\n",
    "    return[(nib.load(datafile), TEs[n]) for n, datafile in enumerate(datafiles)], list(datafiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(echoes: List[Tuple[nib.Nifti1Image, float]], n_vols: int) -> np.array:\n",
    "    \"\"\"Compute weights from echoes described as a list of tuples,\n",
    "    as sorted by org_data.\n",
    "    w(tCNR) = TE * mean / sum(TE * mean) - adapted by K. Garner to reflect Puckett et al formula\n",
    "    \"\"\"\n",
    "    def weight(echo: nib.Nifti1Image, TE: float):\n",
    "        data = echo.get_fdata()\n",
    "        mean = data[..., -n_vols:].mean(axis=-1)\n",
    "        return TE * mean\n",
    "\n",
    "    n_vols  = min(n_vols, echoes[0][0].shape[3])\n",
    "    weights = [weight(echo, TE) for echo, TE in echoes]\n",
    "\n",
    "#    weights = np.stack(weights, axis=-1)\n",
    "#    mu = np.stack([weights.mean(axis=-1), weights.mean(axis=-1)], axis=-1)\n",
    "#    return np.true_divide(weights, mu)\n",
    "    return np.stack(weights, axis=-1) # because numpy average will normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_them(datafiles: List[str],\n",
    "                 TEs: List[int],\n",
    "                 saveweights: bool = True) -> int:\n",
    "    \"\"\"General combine_them routine.\n",
    "    Returns 1 if unmatching acquisitions\n",
    "    Returns 0 upon success\n",
    "    Currently supported algorithms:\n",
    "    - Pucket et al 2018\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the data\n",
    "    me_data, datafiles = org_data(datafiles, TEs)\n",
    "\n",
    "    # Parse the output filenames\n",
    "    datafile = datafiles[0]\n",
    "    datastem = datafile.split(sep=\"_\")\n",
    "    outputname = '_'.join(datastem[0:4] + datastem[5:8])\n",
    "    outputjsonstem = outputname.split(sep=\".\")\n",
    "    outputjson = '.'.join([outputjsonstem[0] , 'json'])\n",
    "\n",
    "    # truncate/match if incomplete runs \n",
    "    all_vols = [echo.shape[3] for echo, TE in me_data]\n",
    "    if len(set(all_vols)) > 1:\n",
    "        echos = np.stack([echo.get_fdata()[:, :, :, 0:min(all_vols)-1] for echo, TE in me_data], axis=-1)\n",
    "        volumes = min(all_vols)\n",
    "    else: \n",
    "        volumes = all_vols[0]\n",
    "        echos = np.stack([echo.get_fdata() for echo, TE in me_data], axis=-1)\n",
    "\n",
    "    # Compute the weights\n",
    "    weights = get_weights(me_data, volumes)\n",
    "    # Make the weights have the appropriate number of volumes.\n",
    "    weights = np.tile(weights[:, :, :, np.newaxis, :], (1, 1, 1, echos.shape[3], 1))\n",
    "\n",
    "\n",
    "    # Combine the images\n",
    "    combined = np.average(echos, axis=-1, weights=weights)      # np.average normalizes the weights. No need to do that manually.\n",
    "    affine   = me_data[0][0].affine\n",
    "    header   = me_data[0][0].header\n",
    "    combined = nib.Nifti1Image(np.nan_to_num(combined), affine, header)\n",
    "    combined.to_filename(str(outputname))\n",
    "\n",
    "    # Add a combined-echo json sidecar-file\n",
    "    outputjson = outputjson\n",
    "    data = {}\n",
    "    data['EchoNumber'] = 1\n",
    "    data['EchoTime'] = np.average([TE for echo, TE in me_data], weights=np.nanmean(weights[..., 0, :], axis=(0,1,2)))  # This seems to be the best we can do (the BIDS validator indicates there has to be a nr here, an empty value generates a warning)   \n",
    "    with open(outputjson, 'w') as json_fid:\n",
    "        json.dump(data, json_fid, indent=4)\n",
    "\n",
    "    # Save the weights\n",
    "    if saveweights: \n",
    "        fname         = datastem[0]+'_combined_weights.nii.gz'\n",
    "        nifti_weights = nib.Nifti1Image(weights[..., 0, :], combined.affine, combined.header)\n",
    "        nifti_weights.to_filename(str(fname))\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_them(datafiles, TEs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
